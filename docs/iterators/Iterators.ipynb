{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b76178b",
   "metadata": {},
   "source": [
    "# Notebook: Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6fa004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleo.dataset.catalog.PHMDataset2018 import PHMDataset2018, FailureType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0145b",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b292f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15Jx9Scq9FqpIGn8jbAQB_lcHSXvIoPzb\n",
      "To: /home/jacopo/.ceruleo/data/phm_data_challenge_2018/raw/phm_data_challenge_2018.tar.gz\n",
      "  2%|‚ñè         | 104M/5.36G [00:08<07:46, 11.3MB/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m PHMDataset2018(\n\u001b[1;32m      2\u001b[0m     tools\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m01_M01\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m04_M01\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ceruleo/dataset/catalog/PHMDataset2018.py:202\u001b[0m, in \u001b[0;36mPHMDataset2018.__init__\u001b[0;34m(self, failure_types, tools, path)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlives_table_filename\u001b[39m.\u001b[39mis_file():\n\u001b[1;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 202\u001b[0m         prepare_raw_dataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_path)\n\u001b[1;32m    203\u001b[0m     prepare_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path)\n\u001b[1;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlives \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlives_table_filename)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ceruleo/dataset/catalog/PHMDataset2018.py:44\u001b[0m, in \u001b[0;36mprepare_raw_dataset\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     42\u001b[0m path\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (path \u001b[39m/\u001b[39m OUTPUT)\u001b[39m.\u001b[39mresolve()\u001b[39m.\u001b[39mis_file():\n\u001b[0;32m---> 44\u001b[0m     download(path)\n\u001b[1;32m     45\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDecompressing  dataset...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39mwith\u001b[39;00m tarfile\u001b[39m.\u001b[39mopen(path \u001b[39m/\u001b[39m OUTPUT, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m tarball:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ceruleo/dataset/catalog/PHMDataset2018.py:33\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload\u001b[39m(path: Path):\n\u001b[1;32m     32\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDownloading dataset...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     gdown\u001b[39m.\u001b[39;49mdownload(URL, \u001b[39mstr\u001b[39;49m(path \u001b[39m/\u001b[39;49m OUTPUT), quiet\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gdown/download.py:270\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume)\u001b[0m\n\u001b[1;32m    268\u001b[0m     pbar \u001b[39m=\u001b[39m tqdm\u001b[39m.\u001b[39mtqdm(total\u001b[39m=\u001b[39mtotal, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    269\u001b[0m t_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 270\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m res\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39mCHUNK_SIZE):\n\u001b[1;32m    271\u001b[0m     f\u001b[39m.\u001b[39mwrite(chunk)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py:750\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    749\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 750\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    751\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[1;32m    752\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:564\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 564\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    566\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    567\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     cache_content \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    509\u001b[0m         amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data\n\u001b[1;32m    510\u001b[0m     ):  \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/contrib/pyopenssl.py:313\u001b[0m, in \u001b[0;36mWrappedSocket.recv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecv_into\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    312\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection\u001b[39m.\u001b[39;49mrecv_into(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[39mexcept\u001b[39;00m OpenSSL\u001b[39m.\u001b[39mSSL\u001b[39m.\u001b[39mSysCallError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    315\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39margs \u001b[39m==\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUnexpected EOF\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/OpenSSL/SSL.py:1821\u001b[0m, in \u001b[0;36mConnection.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     result \u001b[39m=\u001b[39m _lib\u001b[39m.\u001b[39mSSL_peek(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ssl, buf, nbytes)\n\u001b[1;32m   1820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1821\u001b[0m     result \u001b[39m=\u001b[39m _lib\u001b[39m.\u001b[39;49mSSL_read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ssl, buf, nbytes)\n\u001b[1;32m   1822\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_ssl_error(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ssl, result)\n\u001b[1;32m   1824\u001b[0m \u001b[39m# This strange line is all to avoid a memory copy. The buffer protocol\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \u001b[39m# should allow us to assign a CFFI buffer to the LHS of this line, but\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[39m# on CPython 3.3+ that segfaults. As a workaround, we can temporarily\u001b[39;00m\n\u001b[1;32m   1827\u001b[0m \u001b[39m# wrap it in a memoryview.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 104M/5.36G [00:19<07:45, 11.3MB/s]"
     ]
    }
   ],
   "source": [
    "dataset = PHMDataset2018(\n",
    "    tools=['01_M01', '04_M01']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398fb19",
   "metadata": {},
   "source": [
    "### Create a transformer for a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfca18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleo.dataset.analysis.numerical_features import analysis\n",
    "from ceruleo.transformation.functional.transformers import Transformer\n",
    "from ceruleo.transformation.features.selection import ByNameFeatureSelector, ByTypeFeatureSelector\n",
    "from ceruleo.iterators.iterators import RelativeToEnd\n",
    "from ceruleo.transformation.features.slicing import SliceRows\n",
    "from ceruleo.transformation.functional.pipeline.pipeline import make_pipeline\n",
    "from ceruleo.transformation.features.resamplers import IndexMeanResampler\n",
    "from ceruleo.transformation.features.transformation import Clip\n",
    "from ceruleo.transformation.features.slicing import SliceRows\n",
    "from ceruleo.iterators.iterators import RelativeToEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84266b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "   'IONGAUGEPRESSURE', 'ETCHBEAMVOLTAGE', 'ETCHBEAMCURRENT',\n",
    "   'ETCHSUPPRESSORVOLTAGE', 'ETCHSUPPRESSORCURRENT', 'FLOWCOOLFLOWRATE',\n",
    "   'FLOWCOOLPRESSURE', 'ETCHGASCHANNEL1READBACK', 'ETCHPBNGASREADBACK',\n",
    "]\n",
    "transformer = Transformer(\n",
    "    pipelineX=make_pipeline(\n",
    "        ByNameFeatureSelector(features=FEATURES), \n",
    "        Clip(lower=-6, upper=6),\n",
    "        IndexMeanResampler(rule='120s'),\n",
    "        SliceRows(initial=RelativeToEnd(1500))\n",
    "    ), \n",
    "    pipelineY=make_pipeline(\n",
    "        ByNameFeatureSelector(features=['RUL']),  \n",
    "        IndexMeanResampler(rule='120s'),\n",
    "        SliceRows(initial=RelativeToEnd(1500))\n",
    "    )\n",
    ")\n",
    "\n",
    "transformed_dataset = transformer.fit_map(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0fde6",
   "metadata": {},
   "source": [
    "## Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cdd3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleo.iterators.iterators import WindowedDatasetIterator, IterationType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dcb68b",
   "metadata": {},
   "source": [
    "### Forecast iterator\n",
    "\n",
    "The forecast iterator produces as target the values of the Y transformers that start where the X data ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b1dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = WindowedDatasetIterator(\n",
    "    transformed_dataset,\n",
    "    window_size=150,\n",
    "    step=15,\n",
    "    horizon=5,\n",
    "    iteration_type=IterationType.FORECAST # The default value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6374da49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 9), (5, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, sw = next(iterator)\n",
    "(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc855b",
   "metadata": {},
   "source": [
    "It is possible to obtain all the data following the order of the shuffler in an numpy matrix. By default all the data is flattented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb1c760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1679, 1350), (1679, 5), (1679,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, sw = iterator.get_data()\n",
    "(X.shape, y.shape, sw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2fdbf",
   "metadata": {},
   "source": [
    "If flatten is False, we can see the shape of the data. X has 1679 samples, of a window size of 150 and 9 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ac0562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1679, 150, 9), (1679, 5), (1679,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, sw = iterator.get_data(flatten=False)\n",
    "(X.shape, y.shape, sw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb5a95",
   "metadata": {},
   "source": [
    "### Seq to Seq Iterator\n",
    "\n",
    "The seq to seq iterator will return as a target a window of a same size as the input aligned with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618e8547",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = WindowedDatasetIterator(\n",
    "    transformed_dataset,\n",
    "    window_size=150,\n",
    "    step=15,\n",
    "    iteration_type=IterationType.SEQ_TO_SEQ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ffee9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 9), (150, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, sw = next(iterator)\n",
    "(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36202c88",
   "metadata": {},
   "source": [
    "## Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c601250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleo.iterators.batcher import Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e1fd8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 150, 9), (64, 5, 1), (64, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batcher = Batcher.new(\n",
    "    transformed_dataset,\n",
    "    batch_size=64,\n",
    "    window=150,\n",
    "    step=15,\n",
    "    horizon=5\n",
    ")\n",
    "X, y, sw = next(batcher)\n",
    "(X.shape, y.shape, sw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91631a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
